{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import h5py\n",
    "import glob\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1337)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Merge\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras_tqdm import TQDMCallback, TQDMNotebookCallback\n",
    "from PIL import Image\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read test images from local host\n",
    "X1 = np.array(Image.open(\"/home/qw2208/research/left1.png\"))\n",
    "X1 = (X1-np.mean(X1))/np.std(X1)\n",
    "X2 = np.array(Image.open(\"/home/qw2208/research/right1.png\"))\n",
    "X2 = (X2-np.mean(X2))/np.std(X2)\n",
    "# input image dimensions\n",
    "img_rows, img_cols = X1.shape[0], X1.shape[1]\n",
    "input_shape = (1, img_rows, img_cols)\n",
    "\n",
    "X1 = X1.reshape(1, 1, img_rows, img_cols)\n",
    "X2 = X2.reshape(1, 1, img_rows, img_cols)\n",
    "\n",
    "# number of conv filters to use\n",
    "nb_filters = 112\n",
    "\n",
    "# CNN kernel size\n",
    "kernel_size = (3,3)\n",
    "\n",
    "X1 = X1.astype('float32')\n",
    "X2 = X2.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define CNN\n",
    "left_branch = Sequential()\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same', input_shape=input_shape))\n",
    "left_branch.add(Activation('relu'))\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "left_branch.add(Activation('relu'))\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "left_branch.add(Activation('relu'))\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "left_branch.add(Activation('relu'))\n",
    "\n",
    "right_branch = Sequential()\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same', input_shape=input_shape))\n",
    "right_branch.add(Activation('relu'))\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "right_branch.add(Activation('relu'))\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "right_branch.add(Activation('relu'))\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "right_branch.add(Activation('relu')) \n",
    "\n",
    "merged = Merge([left_branch, right_branch], mode='concat', concat_axis=1)\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_cnn_weights(model, filepath):\n",
    "    f = h5py.File(filepath, mode='r')\n",
    "    # g = f['model_weights']\n",
    "    # print f[\"conv2d_1/conv2d_1\"]\n",
    "    weights = []\n",
    "    for i in range(1, 9):\n",
    "        weights.append(f['model_weights/convolution2d_{}/convolution2d_{}_W/'.format(i, i)][()])\n",
    "        weights.append(f['model_weights/convolution2d_{}/convolution2d_{}_b/'.format(i, i)][()])\n",
    "        print weights[0].shape\n",
    "    model.set_weights(weights)\n",
    "    f.close()\n",
    "    \n",
    "# load weight for first cnn part\n",
    "load_cnn_weights(cnn, \"/home/qw2208/research/weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape is =====================> (1, 224, 151, 500)\n"
     ]
    }
   ],
   "source": [
    "# predict feature map output and later will do d times fc\n",
    "output_cnn = cnn.predict([X1, X2])\n",
    "print \"output shape is =====================>\", output_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27104, 384)  and  (384,)\n",
      "(27104, 384)  and  (384,)\n",
      "(27104, 384)  and  (384,)\n",
      "(27104, 384)  and  (384,)\n"
     ]
    }
   ],
   "source": [
    "# set network params for fc\n",
    "nb_filters_fc = 384\n",
    "kernel_size = (11, 11) \n",
    "input_shape = (nb_filters*2, None, None)\n",
    "\n",
    "def load_fc_weights(filepath):\n",
    "    f = h5py.File(filepath, mode='r')\n",
    "    weights = []\n",
    "    for i in range(1, 5):\n",
    "        weight = np.array(f['model_weights/dense_{}/dense_{}_W'.format(i, i)][()])\n",
    "        bias = f['model_weights/dense_{}/dense_{}_b'.format(i, i)][()]\n",
    "        weights.append(weight)\n",
    "        weights.append(bias)\n",
    "        print weights[0].shape, \" and \", weights[1].shape\n",
    "    return weights\n",
    "\n",
    "weights_fc = load_fc_weights(\"/home/qw2208/research/weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create original fully-connected layers for training but now fully-conv layers\n",
    "\n",
    "fc = Sequential()\n",
    "fc.add(Convolution2D(nb_filters_fc, kernel_size[0], kernel_size[1], border_mode='same', activation='relu', input_shape=input_shape, weights=[np.transpose(weights_fc[0]).reshape(nb_filters_fc, 224, kernel_size[0], kernel_size[1]), weights_fc[1]]))\n",
    "fc.add(Convolution2D(nb_filters_fc, 1, 1, border_mode='same', activation='relu', weights=[np.transpose(weights_fc[2]).reshape(nb_filters_fc, nb_filters_fc, 1, 1), weights_fc[3]]))\n",
    "fc.add(Convolution2D(nb_filters_fc, 1, 1, border_mode='same', activation='relu', weights=[np.transpose(weights_fc[4]).reshape(nb_filters_fc, nb_filters_fc, 1, 1), weights_fc[5]]))\n",
    "fc.add(Convolution2D(1, 1, 1, border_mode='same', activation='sigmoid', weights=[np.transpose(weights_fc[6]).reshape(1, nb_filters_fc, 1, 1), weights_fc[7]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 151, 499)\n",
      "[[[[  8.52139771e-01   8.70309889e-01   6.87681794e-01 ...,\n",
      "      1.00000000e+00   2.88798565e-05   6.03574889e-28]\n",
      "   [  8.85487378e-01   5.06168067e-01   5.33672154e-01 ...,\n",
      "      7.74453223e-01   2.74034619e-01   3.34924995e-03]\n",
      "   [  2.58825034e-01   3.54635537e-01   3.36280793e-01 ...,\n",
      "      7.15397000e-01   5.10844946e-01   4.54057604e-01]\n",
      "   ..., \n",
      "   [  3.35182700e-33   7.82994857e-24   2.32259216e-26 ...,\n",
      "      3.12883765e-01   2.34719917e-01   2.99170047e-01]\n",
      "   [  0.00000000e+00   8.56515306e-36   2.25054793e-35 ...,\n",
      "      5.61878800e-01   4.81298417e-01   5.26802421e-01]\n",
      "   [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,\n",
      "      5.00807226e-01   5.93995929e-01   5.25908530e-01]]]]\n",
      "(1, 224, 151, 498)\n",
      "[[[[  9.51602995e-01   9.53921378e-01   9.27291512e-01 ...,\n",
      "      1.00000000e+00   1.00000000e+00   4.22677573e-07]\n",
      "   [  1.00155557e-02   5.21128178e-01   6.31566405e-01 ...,\n",
      "      9.17167246e-01   8.86656940e-01   9.86039400e-01]\n",
      "   [  9.55973845e-03   3.49204391e-01   3.44639450e-01 ...,\n",
      "      8.06612372e-01   7.75040746e-01   6.59421444e-01]\n",
      "   ..., \n",
      "   [  6.63634798e-32   1.14030189e-25   1.18085731e-15 ...,\n",
      "      4.78839010e-01   3.28774214e-01   2.62739986e-01]\n",
      "   [  0.00000000e+00   6.11656410e-38   7.54686651e-32 ...,\n",
      "      5.75106382e-01   6.21052265e-01   5.38001955e-01]\n",
      "   [  0.00000000e+00   0.00000000e+00   5.85370528e-37 ...,\n",
      "      5.54641187e-01   6.10914826e-01   5.86028337e-01]]]]\n",
      "(1, 224, 151, 497)\n",
      "[[[[  8.79555717e-02   9.36765671e-01   8.22211266e-01 ...,\n",
      "      9.43641126e-01   1.00000000e+00   9.99997377e-01]\n",
      "   [  3.49881337e-03   6.68254912e-01   5.49221575e-01 ...,\n",
      "      9.99813616e-01   1.00000000e+00   1.00000000e+00]\n",
      "   [  2.37474591e-03   3.44277501e-01   3.36576223e-01 ...,\n",
      "      9.73219693e-01   9.97174740e-01   1.00000000e+00]\n",
      "   ..., \n",
      "   [  2.59372957e-33   9.57815592e-19   1.07586863e-10 ...,\n",
      "      5.28606057e-01   5.36035299e-01   2.89335370e-01]\n",
      "   [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,\n",
      "      5.81980944e-01   6.86763406e-01   5.72174728e-01]\n",
      "   [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,\n",
      "      6.54544711e-01   6.65128589e-01   4.69609380e-01]]]]\n",
      "(1, 224, 151, 496)\n",
      "[[[[  2.47205864e-03   2.85268426e-01   5.87630093e-01 ...,\n",
      "      7.84206629e-01   9.98660445e-01   1.75355706e-06]\n",
      "   [  4.26189788e-02   6.92138076e-01   5.51423550e-01 ...,\n",
      "      9.43043411e-01   1.00000000e+00   1.00000000e+00]\n",
      "   [  1.24330604e-02   3.35939586e-01   3.66531581e-01 ...,\n",
      "      9.88205433e-01   1.00000000e+00   1.00000000e+00]\n",
      "   ..., \n",
      "   [  1.39845995e-25   4.76672873e-16   3.60395181e-17 ...,\n",
      "      4.98961121e-01   5.99146664e-01   5.76533139e-01]\n",
      "   [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,\n",
      "      5.23777485e-01   8.13229620e-01   8.82567465e-01]\n",
      "   [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,\n",
      "      5.44263959e-01   8.08742523e-01   6.67866766e-01]]]]\n",
      "(1, 224, 151, 495)\n",
      "[[[[  1.58712210e-05   3.88715148e-01   3.83697838e-01 ...,\n",
      "      7.05444098e-01   7.01698303e-01   7.72785915e-12]\n",
      "   [  1.54043653e-03   6.42876148e-01   4.11848426e-01 ...,\n",
      "      6.82729781e-01   9.87977862e-01   9.99252617e-01]\n",
      "   [  8.81200947e-04   3.32194299e-01   3.21010113e-01 ...,\n",
      "      7.77384341e-01   1.00000000e+00   1.00000000e+00]\n",
      "   ..., \n",
      "   [  1.38356009e-25   8.74188140e-22   4.18623985e-26 ...,\n",
      "      4.25005972e-01   5.69445431e-01   6.16636872e-01]\n",
      "   [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,\n",
      "      4.00792301e-01   6.53891683e-01   9.93139565e-01]\n",
      "   [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,\n",
      "      3.79530281e-01   5.21102190e-01   7.93211341e-01]]]]\n"
     ]
    }
   ],
   "source": [
    "# input feature map into fully-conv(test phase) layer for d times\n",
    "d_max = 5\n",
    "vol = np.zeros((img_rows, img_cols, d_max), dtype=np.float)\n",
    "for d in range(1, d_max+1):\n",
    "    input_fc_left = output_cnn[:, 0:112, :, d:]\n",
    "    input_fc_right = output_cnn[:, 112:, :, 0:-d]\n",
    "    input_fc = np.concatenate((input_fc_left, input_fc_right), axis=1)\n",
    "    \n",
    "    print input_fc.shape\n",
    "    output = fc.predict(input_fc)\n",
    "    print output\n",
    "    vol[:, d:, d-1] = output.squeeze()\n",
    "#    print \"============================= \", d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 500) \n",
      "  [[0 0 1 ..., 0 1 2]\n",
      " [0 0 0 ..., 2 2 2]\n",
      " [0 0 0 ..., 3 3 2]\n",
      " ..., \n",
      " [0 0 0 ..., 2 3 4]\n",
      " [0 0 0 ..., 2 3 4]\n",
      " [0 0 0 ..., 2 3 4]]\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "result_index = np.argmax(vol, axis=2)\n",
    "print result_index.shape, \"\\n \", result_index\n",
    "print \"Finished!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
