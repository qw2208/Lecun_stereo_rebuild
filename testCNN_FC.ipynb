{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K40c (CNMeM is enabled with initial size: 95.0% of memory, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import h5py\n",
    "import glob\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1337)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Merge\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras_tqdm import TQDMCallback, TQDMNotebookCallback\n",
    "from PIL import Image\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read test images from local host\n",
    "X1 = np.array(Image.open(\"/home/qw2208/research/left1.png\"))\n",
    "X1 = (X1-np.mean(X1))/np.std(X1)\n",
    "X2 = np.array(Image.open(\"/home/qw2208/research/right1.png\"))\n",
    "X2 = (X2-np.mean(X2))/np.std(X2)\n",
    "# input image dimensions\n",
    "img_rows, img_cols = X1.shape[0], X1.shape[1]\n",
    "input_shape = (1, img_rows, img_cols)\n",
    "\n",
    "X1 = X1.reshape(1, 1, img_rows, img_cols)\n",
    "X2 = X2.reshape(1, 1, img_rows, img_cols)\n",
    "\n",
    "# number of conv filters to use\n",
    "nb_filters = 112\n",
    "\n",
    "# CNN kernel size\n",
    "kernel_size = (3,3)\n",
    "\n",
    "X1 = X1.astype('float32')\n",
    "X2 = X2.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define CNN\n",
    "left_branch = Sequential()\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same', input_shape=input_shape))\n",
    "left_branch.add(Activation('relu'))\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "left_branch.add(Activation('relu'))\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "left_branch.add(Activation('relu'))\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "left_branch.add(Activation('relu'))\n",
    "\n",
    "right_branch = Sequential()\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same', input_shape=input_shape))\n",
    "right_branch.add(Activation('relu'))\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "right_branch.add(Activation('relu'))\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "right_branch.add(Activation('relu'))\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "right_branch.add(Activation('relu')) \n",
    "\n",
    "merged = Merge([left_branch, right_branch], mode='concat', concat_axis=1)\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n",
      "(112, 1, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_cnn_weights(model, filepath):\n",
    "    f = h5py.File(filepath, mode='r')\n",
    "    # g = f['model_weights']\n",
    "    # print f[\"conv2d_1/conv2d_1\"]\n",
    "    weights = []\n",
    "    for i in range(1, 9):\n",
    "        weights.append(f['model_weights/convolution2d_{}/convolution2d_{}_W/'.format(i, i)][()])\n",
    "        weights.append(f['model_weights/convolution2d_{}/convolution2d_{}_b/'.format(i, i)][()])\n",
    "        print weights[0].shape\n",
    "    model.set_weights(weights)\n",
    "    f.close()\n",
    "    \n",
    "# load weight for first cnn part\n",
    "load_cnn_weights(cnn, \"/home/qw2208/research/weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape is =====================> (1, 224, 150, 500)\n",
      "[[[[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          1.49048579 ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.8347919  ...,  0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "# predict feature map output and later will do d times fc\n",
    "output_cnn = cnn.predict([X1, X2])\n",
    "print \"output shape is =====================>\", output_cnn.shape\n",
    "print output_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27104, 384)  and  (384,)\n",
      "(27104, 384)  and  (384,)\n",
      "(27104, 384)  and  (384,)\n",
      "(27104, 384)  and  (384,)\n"
     ]
    }
   ],
   "source": [
    "# set network params for fc\n",
    "nb_filters_fc = 384\n",
    "kernel_size = (11, 11) \n",
    "input_shape = (nb_filters*2, None, None)\n",
    "\n",
    "def load_fc_weights(filepath):\n",
    "    f = h5py.File(filepath, mode='r')\n",
    "    weights = []\n",
    "    for i in range(1, 5):\n",
    "        weight = np.array(f['model_weights/dense_{}/dense_{}_W'.format(i, i)][()])\n",
    "        bias = (f['model_weights/dense_{}/dense_{}_b'.format(i, i)][()])\n",
    "        weights.append(weight)\n",
    "        weights.append(bias)\n",
    "        print weights[0].shape, \" and \", weights[1].shape\n",
    "    return weights\n",
    "\n",
    "weights_fc = load_fc_weights(\"/home/qw2208/research/weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create original fully-connected layers for training but now fully-conv layers\n",
    "\n",
    "fc = Sequential()\n",
    "fc.add(Convolution2D(nb_filters_fc, kernel_size[0], kernel_size[1], border_mode='same', activation='relu', input_shape=input_shape, weights=[np.transpose(weights_fc[0]).reshape(nb_filters_fc, 224, kernel_size[0], kernel_size[1]), weights_fc[1]]))\n",
    "fc.add(Convolution2D(nb_filters_fc, 1, 1, border_mode='same', activation='relu', weights=[np.transpose(weights_fc[2]).reshape(nb_filters_fc, nb_filters_fc, 1, 1), weights_fc[3]]))\n",
    "fc.add(Convolution2D(nb_filters_fc, 1, 1, border_mode='same', activation='relu', weights=[np.transpose(weights_fc[4]).reshape(nb_filters_fc, nb_filters_fc, 1, 1), weights_fc[5]]))\n",
    "fc.add(Convolution2D(1, 1, 1, border_mode='same', activation='sigmoid', weights=[np.transpose(weights_fc[6]).reshape(1, nb_filters_fc, 1, 1), weights_fc[7]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 150, 499)\n",
      "[[[[  4.72703236e-14   2.37485409e-01   9.38353017e-02 ...,\n",
      "      9.95979309e-01   9.99969602e-01   1.00000000e+00]\n",
      "   [  8.79311800e-01   2.71951705e-01   9.41470563e-02 ...,\n",
      "      5.43973565e-01   9.99990344e-01   1.00000000e+00]\n",
      "   [  9.90601184e-05   8.80735219e-02   6.74693212e-02 ...,\n",
      "      2.20499948e-01   3.24341774e-01   9.62358773e-01]\n",
      "   ..., \n",
      "   [  2.48303367e-15   2.79461551e-06   5.25644496e-02 ...,\n",
      "      7.39311218e-01   5.56661069e-01   4.85981494e-01]\n",
      "   [  1.29970734e-21   3.78756374e-02   1.00000000e+00 ...,\n",
      "      6.71559334e-01   6.04659379e-01   7.14984953e-01]\n",
      "   [  1.14527445e-35   4.18575087e-23   1.25275701e-09 ...,\n",
      "      5.46086252e-01   5.99015892e-01   9.83936191e-01]]]]\n",
      "(1, 224, 150, 498)\n",
      "[[[[  6.87827009e-12   5.64412767e-05   1.93624958e-01 ...,\n",
      "      9.14061248e-01   1.00000000e+00   1.00000000e+00]\n",
      "   [  9.84483540e-01   1.68833584e-01   1.33671716e-01 ...,\n",
      "      3.97321224e-01   9.99863982e-01   1.00000000e+00]\n",
      "   [  1.82073491e-04   8.26186910e-02   4.69824672e-02 ...,\n",
      "      2.17853040e-01   3.85835022e-01   9.35367823e-01]\n",
      "   ..., \n",
      "   [  3.12553672e-12   1.39877498e-01   4.26905090e-03 ...,\n",
      "      9.03158724e-01   7.41862416e-01   7.50568092e-01]\n",
      "   [  2.78751788e-20   1.00000000e+00   1.00000000e+00 ...,\n",
      "      7.42114961e-01   6.03288710e-01   6.76539898e-01]\n",
      "   [  1.04138950e-34   1.69285655e-10   3.89639827e-05 ...,\n",
      "      5.62315881e-01   4.22818571e-01   9.37427759e-01]]]]\n",
      "(1, 224, 150, 497)\n",
      "[[[[  1.02731420e-21   8.54562750e-05   2.57160902e-01 ...,\n",
      "      9.23893571e-01   9.99999642e-01   1.00000000e+00]\n",
      "   [  1.45326974e-03   2.35122070e-01   1.61718801e-01 ...,\n",
      "      3.55668634e-01   9.98984635e-01   1.00000000e+00]\n",
      "   [  2.98622342e-11   8.65018144e-02   4.14893068e-02 ...,\n",
      "      1.58144876e-01   3.55681598e-01   9.66733336e-01]\n",
      "   ..., \n",
      "   [  9.13531985e-05   9.99481738e-01   9.99298573e-01 ...,\n",
      "      7.30460703e-01   6.80737734e-01   8.64666343e-01]\n",
      "   [  7.22882865e-11   1.00000000e+00   1.00000000e+00 ...,\n",
      "      5.50809205e-01   5.81528246e-01   6.28035426e-01]\n",
      "   [  2.93829134e-21   5.41975163e-03   1.30051660e-04 ...,\n",
      "      5.01425385e-01   4.29166943e-01   6.75070286e-01]]]]\n",
      "(1, 224, 150, 496)\n",
      "[[[[  2.06106926e-22   3.58197462e-06   3.24977905e-01 ...,\n",
      "      9.85211253e-01   9.99999523e-01   1.00000000e+00]\n",
      "   [  3.01137276e-04   2.63500810e-01   1.75487578e-01 ...,\n",
      "      2.81916201e-01   9.91250992e-01   1.00000000e+00]\n",
      "   [  1.81579426e-12   7.02092722e-02   3.98219787e-02 ...,\n",
      "      9.69079435e-02   1.95311874e-01   9.66084480e-01]\n",
      "   ..., \n",
      "   [  1.30741872e-04   1.00000000e+00   1.00000000e+00 ...,\n",
      "      6.01043105e-01   5.31076491e-01   5.87169051e-01]\n",
      "   [  4.60980247e-11   1.00000000e+00   1.00000000e+00 ...,\n",
      "      4.67830777e-01   4.54589128e-01   4.64837193e-01]\n",
      "   [  1.17821150e-15   9.67825711e-01   2.80330759e-11 ...,\n",
      "      4.40998942e-01   4.46119130e-01   4.60806280e-01]]]]\n",
      "(1, 224, 150, 495)\n",
      "[[[[  7.42595101e-25   3.21934340e-06   2.36130610e-01 ...,\n",
      "      9.49231267e-01   9.99990225e-01   1.00000000e+00]\n",
      "   [  7.56014879e-06   3.46541375e-01   1.56068519e-01 ...,\n",
      "      1.93758026e-01   3.74255002e-01   9.98140812e-01]\n",
      "   [  3.58706120e-13   6.74500763e-02   2.42390446e-02 ...,\n",
      "      6.93873242e-02   8.92078876e-02   2.85018682e-01]\n",
      "   ..., \n",
      "   [  6.05252571e-03   1.00000000e+00   1.00000000e+00 ...,\n",
      "      5.33974886e-01   5.17905831e-01   5.40124714e-01]\n",
      "   [  5.28613486e-10   1.00000000e+00   9.99997735e-01 ...,\n",
      "      4.79630053e-01   4.44118887e-01   4.44236666e-01]\n",
      "   [  6.88072946e-18   1.46402491e-11   4.94459371e-08 ...,\n",
      "      4.22065258e-01   3.94935817e-01   4.64872539e-01]]]]\n"
     ]
    }
   ],
   "source": [
    "# input feature map into fully-conv(test phase) layer for d times\n",
    "d_max = 5\n",
    "vol = np.zeros((img_rows, img_cols, d_max), dtype=np.float)\n",
    "for d in range(1, d_max+1):\n",
    "    input_fc_left = output_cnn[:, 0:112, :, d:]\n",
    "    input_fc_right = output_cnn[:, 112:, :, 0:-d]\n",
    "    input_fc = np.concatenate((input_fc_left, input_fc_right), axis=1)\n",
    "    \n",
    "    print input_fc.shape\n",
    "    output = fc.predict(input_fc)\n",
    "    print output\n",
    "    vol[:, d:, d-1] = output.squeeze()\n",
    "#    print \"============================= \", d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 500) \n",
      "  [[0 0 0 ..., 0 1 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 2]\n",
      " ..., \n",
      " [0 0 0 ..., 1 1 2]\n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 1 0 0]]\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "result_index = np.argmax(vol, axis=2)\n",
    "print result_index.shape, \"\\n \", result_index\n",
    "result_index = result_index.astype('int16')\n",
    "im = Image.fromarray(result_index)\n",
    "im.convert('RGB').save(\"disp.png\")\n",
    "print \"Finished!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
