{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import h5py\n",
    "import glob\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1337)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Merge\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras_tqdm import TQDMCallback, TQDMNotebookCallback\n",
    "from PIL import Image\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read test images from local host\n",
    "X1 = np.array(Image.open(\"/home/qw2208/research/left1.png\"))\n",
    "X1 = (X1-np.mean(X1))/np.std(X1)\n",
    "X2 = np.array(Image.open(\"/home/qw2208/research/right1.png\"))\n",
    "X2 = (X2-np.mean(X2))/np.std(X2)\n",
    "# input image dimensions\n",
    "img_rows, img_cols = X1.shape[0], X1.shape[1]\n",
    "input_shape = (1, img_rows, img_cols)\n",
    "\n",
    "X1 = X1.reshape(1, 1, img_rows, img_cols)\n",
    "X2 = X2.reshape(1, 1, img_rows, img_cols)\n",
    "\n",
    "# number of conv filters to use\n",
    "nb_filters = 112\n",
    "\n",
    "# CNN kernel size\n",
    "kernel_size = (3,3)\n",
    "\n",
    "X1 = X1.astype('float32')\n",
    "X2 = X2.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define CNN\n",
    "left_branch = Sequential()\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same', input_shape=input_shape))\n",
    "#left_branch.add(BatchNormalization(axis=1))\n",
    "left_branch.add(ELU()) \n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "#left_branch.add(BatchNormalization(axis=1))\n",
    "left_branch.add(ELU())\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "#left_branch.add(BatchNormalization(axis=1))\n",
    "left_branch.add(ELU())\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "#left_branch.add(BatchNormalization(axis=1))\n",
    "left_branch.add(ELU())\n",
    "\n",
    "right_branch = Sequential()\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same', input_shape=input_shape))\n",
    "#right_branch.add(BatchNormalization(axis=1))\n",
    "right_branch.add(ELU())\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "#right_branch.add(BatchNormalization(axis=1))\n",
    "right_branch.add(ELU())\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "#right_branch.add(BatchNormalization(axis=1))\n",
    "right_branch.add(ELU())\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "#right_branch.add(BatchNormalization(axis=1))\n",
    "right_branch.add(ELU())\n",
    "\n",
    "merged = Merge([left_branch, right_branch], mode='concat', concat_axis=1)\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_cnn_weights(model, filepath):\n",
    "    f = h5py.File(filepath, mode='r')\n",
    "    # g = f['model_weights']\n",
    "    # print f[\"conv2d_1/conv2d_1\"]\n",
    "    weights = []\n",
    "    for i in range(1, 9):\n",
    "        weights.append(f['model_weights/convolution2d_{}/convolution2d_{}_W/'.format(i, i)][()])\n",
    "        weights.append(f['model_weights/convolution2d_{}/convolution2d_{}_b/'.format(i, i)][()])\n",
    "#         weights.append(f['model_weights/batchnormalization_{}/batchnormalization_{}_beta/'.format(i-2, i-2)][()])\n",
    "#         weights.append(f['model_weights/batchnormalization_{}/batchnormalization_{}_gamma/'.format(i-2, i-2)][()])\n",
    "#         weights.append(f['model_weights/batchnormalization_{}/batchnormalization_{}_running_mean/'.format(i-2, i-2)][()])\n",
    "#         weights.append(f['model_weights/batchnormalization_{}/batchnormalization_{}_running_std/'.format(i-2, i-2)][()])\n",
    "    # print len(weights)\n",
    "    model.set_weights(weights)\n",
    "    f.close()\n",
    "    \n",
    "# load weight for first cnn part\n",
    "load_cnn_weights(cnn, \"/home/qw2208/research/weightsOne.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# predict feature map output and later will do d times fc\n",
    "output_cnn = cnn.predict([X1, X2])\n",
    "print \"output shape is =====================>\", output_cnn.shape\n",
    "print (output_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training neural networks consist of CNNs instead of fully connected layers. Parameters can be loaded into the network for testing directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set network params for fc\n",
    "nb_filters_fc = 384\n",
    "kernel_size = (9, 9) \n",
    "input_shape = (nb_filters*2, None, None)\n",
    "\n",
    "def load_fc_weights(filepath):\n",
    "    f = h5py.File(filepath, mode='r')\n",
    "    weights = []\n",
    "    for i in range(9, 13):\n",
    "        weights.append(f['model_weights/convolution2d_{}/convolution2d_{}_W/'.format(i, i)][()])\n",
    "        weights.append(f['model_weights/convolution2d_{}/convolution2d_{}_b/'.format(i, i)][()])\n",
    "#         weights.append(f['model_weights/batchnormalization_{}/batchnormalization_{}_beta/'.format(i-2, i-2)][()])\n",
    "#         weights.append(f['model_weights/batchnormalization_{}/batchnormalization_{}_gamma/'.format(i-2, i-2)][()])\n",
    "#         weights.append(f['model_weights/batchnormalization_{}/batchnormalization_{}_running_mean/'.format(i-2, i-2)][()])\n",
    "#         weights.append(f['model_weights/batchnormalization_{}/batchnormalization_{}_running_std/'.format(i-2, i-2)][()])\n",
    "    return weights\n",
    "\n",
    "weights_fc = load_fc_weights(\"/home/qw2208/research/weightsOne.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create original fully-connected layers for training but now fully-conv layers\n",
    "\n",
    "fc = Sequential()\n",
    "fc.add(Convolution2D(nb_filters_fc, kernel_size[0], kernel_size[1], border_mode='valid', input_shape=input_shape))\n",
    "# fc.add(BatchNormalization(axis=1))\n",
    "fc.add(ELU())\n",
    "fc.add(Convolution2D(nb_filters_fc, 1, 1, border_mode='valid'))\n",
    "# fc.add(BatchNormalization(axis=1))\n",
    "fc.add(ELU())\n",
    "fc.add(Convolution2D(nb_filters_fc, 1, 1, border_mode='valid'))\n",
    "# fc.add(BatchNormalization(axis=1))\n",
    "fc.add(ELU())\n",
    "fc.add(Convolution2D(1, 1, 1, border_mode='valid', activation='sigmoid'))\n",
    "\n",
    "fc.set_weights(weights_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# input feature map into fully-conv(test phase) layer for d times\n",
    "d_max = 200\n",
    "vol = np.zeros((img_rows-8, img_cols-8, d_max), dtype=np.float)\n",
    "for d in range(1, d_max+1):\n",
    "    input_fc_left = output_cnn[:, 0:112, :, d:]\n",
    "    input_fc_right = output_cnn[:, 112:, :, 0:-d]\n",
    "    input_fc = np.concatenate((input_fc_left, input_fc_right), axis=1)\n",
    "    \n",
    "    print input_fc.shape\n",
    "    output = fc.predict(input_fc)\n",
    "    print output\n",
    "    vol[:, d:, d-1] = output.squeeze()\n",
    "#    print \"============================= \", d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result_index = np.argmax(vol, axis=2)\n",
    "print result_index.shape, \"\\n \", result_index\n",
    "result_index = result_index.astype('int16')\n",
    "im = Image.fromarray(result_index)\n",
    "im.convert('RGB').save(\"disp.png\")\n",
    "print \"Finished!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
