{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K40c (CNMeM is enabled with initial size: 95.0% of memory, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import h5py\n",
    "import glob\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1337)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Merge\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras_tqdm import TQDMCallback, TQDMNotebookCallback\n",
    "from PIL import Image\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define the parameters for training\n",
    "batch_size = 128\n",
    "nb_classes = 2\n",
    "nb_epoch = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 9, 9\n",
    "\n",
    "# Volume of the training set\n",
    "sample_number = 100000\n",
    "\n",
    "# number of conv filters to use\n",
    "nb_filters = 112\n",
    "\n",
    "# CNN kernel size\n",
    "kernel_size = (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for loading the training set:  91.7614600658\n"
     ]
    }
   ],
   "source": [
    "# load the patches\n",
    "X1_train = np.zeros((sample_number, img_rows, img_cols))\n",
    "X2_train = np.zeros((sample_number, img_rows, img_cols))\n",
    "y_train = np.zeros((sample_number,))\n",
    "\n",
    "tic = time.time()\n",
    "# Load the training set.\n",
    "hdf5TrainPatchesPath = \"/home/qw2208/research/trainPatchesOne.hdf5\"\n",
    "with h5py.File(hdf5TrainPatchesPath, \"r\") as f1:\n",
    "    for i in xrange(sample_number/2):\n",
    "        X1_train[2*i,:,:] = f1['left/'+str(i)][()]\n",
    "        X1_train[(2*i+1),:,:] = f1['left/'+str(i)][()]\n",
    "        X2_train[2*i,:,:] = f1['rightNeg/'+str(i)][()]\n",
    "        X2_train[(2*i+1),:,:] = f1['rightPos/'+str(i)][()]\n",
    "        y_train[2*i] = 0\n",
    "        y_train[2*i+1] = 1\n",
    "    \n",
    "toc = time.time()\n",
    "print \"Time for loading the training set: \", toc-tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here some additional preprocess methods like rotation etc. could be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Resize the dataset (Trivial)\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    X1_train = X1_train.reshape(X1_train.shape[0], 1, img_rows, img_cols)\n",
    "    X2_train = X2_train.reshape(X2_train.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1,img_rows, img_cols)\n",
    "else:\n",
    "    X1_train = X1_train.reshape(X1_train.shape[0], img_rows, img_cols, 1)\n",
    "    X2_train = X2_train.reshape(X2_train.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Briefly check some patches.\n",
    "# Positive-matching patches are expected to be of similar features.\n",
    "# We store two left patches in X1_train.\n",
    "# One for matching the positve right patch in X2_train. \n",
    "# The other for matching negative right patch in X2_train.\n",
    "\n",
    "# for i in xrange(20,30):\n",
    "#     print 'Check {}'.format(i-19)\n",
    "#     print X1_train[2*i][0]\n",
    "#     # print (X1_train[2*i+1][0]-X2_train[2*i+1][0])\n",
    "\n",
    "X1_train = X1_train.astype('float32')\n",
    "X2_train = X2_train.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This neural network is working finely and ends up with a training accuracy of more than 90%. Some units are missing:\n",
    "1. Data augment: Rotation, transformation and etc.\n",
    "2. Volume of the training set. \n",
    "3. I haven't split the training set into training set and validation set. And the evaluation of the network is based on the whole training set, which is not permitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(3):\n",
    "    y_train = np.expand_dims(y_train,axis=2)\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e79f71ed49242429a26915d75b0d8a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec98f7d6da4463b80016ad0602feee7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42ff8fbba5f468a8ad3256a02a4fc10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac047fb7713649c2a635244bc1f700ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2314a3a7278454fb970839b5eff0266"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58dfd44032a34aaeb8d0c6a7870957a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428a45400c0c4cb78d71928ac87ff89f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c643bd3f6682476d8cd615f2b7943e73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5688435f4841baa096ff468b16183f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1f447771384720991b5a0ad7461f7b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79746c57f5344953aa390474e02c069f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('Test score: ', 0.16615705102324485)\n",
      "('Test accuracy: ', 0.92451000000000005)\n"
     ]
    }
   ],
   "source": [
    "# https://keras-cn.readthedocs.io/en/latest/getting_started/sequential_model/#merge\n",
    "left_branch = Sequential()\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same', input_shape=input_shape))\n",
    "#left_branch.add(BatchNormalization(axis=1))\n",
    "left_branch.add(ELU())\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "#left_branch.add(BatchNormalization(axis=1))\n",
    "left_branch.add(ELU())\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "#left_branch.add(BatchNormalization(axis=1))\n",
    "left_branch.add(ELU())\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "#left_branch.add(BatchNormalization(axis=1))\n",
    "left_branch.add(ELU())\n",
    "\n",
    "right_branch = Sequential()\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same', input_shape=input_shape))\n",
    "#right_branch.add(BatchNormalization(axis=1))\n",
    "right_branch.add(ELU())\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "#right_branch.add(BatchNormalization(axis=1))\n",
    "right_branch.add(ELU())\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "#right_branch.add(BatchNormalization(axis=1))\n",
    "right_branch.add(ELU())\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "#right_branch.add(BatchNormalization(axis=1))\n",
    "right_branch.add(ELU()) \n",
    "\n",
    "merged = Merge([left_branch, right_branch], mode='concat', concat_axis=1)\n",
    "nb_filters_fc = 384\n",
    "\n",
    "fc = Sequential()\n",
    "fc.add(merged)\n",
    "fc.add(Convolution2D(nb_filters_fc, img_rows, img_cols, border_mode='valid'))\n",
    "#fc.add(BatchNormalization(axis=1))\n",
    "fc.add(ELU())\n",
    "fc.add(Convolution2D(nb_filters_fc, 1,1, border_mode='valid'))\n",
    "#fc.add(BatchNormalization(axis=1))\n",
    "fc.add(ELU())\n",
    "fc.add(Convolution2D(nb_filters_fc, 1,1, border_mode='valid'))\n",
    "#fc.add(BatchNormalization(axis=1))\n",
    "fc.add(ELU())\n",
    "fc.add(Convolution2D(1, 1, 1, border_mode='valid', activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=1e-4, decay=1e-5)\n",
    "# fc.load_weights('/home/qw2208/research/weightsOne.hdf5')\n",
    "fc.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "fc.fit([X1_train,X2_train], y_train, validation_split=0.1, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0, shuffle=True, callbacks=[TQDMNotebookCallback()])\n",
    "# Evaluate the result based on the training set\n",
    "score = fc.evaluate([X1_train,X2_train], y_train, verbose=0)\n",
    "# print score.shape\n",
    "print('Test score: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 112, 9, 9)     1120                                         \n",
      "____________________________________________________________________________________________________\n",
      "elu_1 (ELU)                      (None, 112, 9, 9)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 112, 9, 9)     113008                                       \n",
      "____________________________________________________________________________________________________\n",
      "elu_2 (ELU)                      (None, 112, 9, 9)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 112, 9, 9)     113008                                       \n",
      "____________________________________________________________________________________________________\n",
      "elu_3 (ELU)                      (None, 112, 9, 9)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 112, 9, 9)     113008                                       \n",
      "____________________________________________________________________________________________________\n",
      "elu_4 (ELU)                      (None, 112, 9, 9)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 112, 9, 9)     1120                                         \n",
      "____________________________________________________________________________________________________\n",
      "elu_5 (ELU)                      (None, 112, 9, 9)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 112, 9, 9)     113008                                       \n",
      "____________________________________________________________________________________________________\n",
      "elu_6 (ELU)                      (None, 112, 9, 9)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 112, 9, 9)     113008                                       \n",
      "____________________________________________________________________________________________________\n",
      "elu_7 (ELU)                      (None, 112, 9, 9)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 112, 9, 9)     113008                                       \n",
      "____________________________________________________________________________________________________\n",
      "elu_8 (ELU)                      (None, 112, 9, 9)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 384, 1, 1)     6967680     merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "elu_9 (ELU)                      (None, 384, 1, 1)     0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 384, 1, 1)     147840      elu_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_10 (ELU)                     (None, 384, 1, 1)     0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 384, 1, 1)     147840      elu_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "elu_11 (ELU)                     (None, 384, 1, 1)     0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 1, 1, 1)       385         elu_11[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 7944033\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fc.save('/home/qw2208/research/weightsOne.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
