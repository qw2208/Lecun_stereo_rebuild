{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import h5py\n",
    "import glob\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1337)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Merge\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras_tqdm import TQDMCallback, TQDMNotebookCallback\n",
    "from PIL import Image\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define the parameters for training\n",
    "batch_size = 128\n",
    "nb_classes = 2\n",
    "nb_epoch = 20\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 11, 11\n",
    "\n",
    "# Volume of the training set\n",
    "sample_number = 100000\n",
    "\n",
    "# number of conv filters to use\n",
    "nb_filters = 112\n",
    "\n",
    "# CNN kernel size\n",
    "kernel_size = (3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Loading time is about 90s for 100,000 patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the patches\n",
    "X1_train = np.zeros((sample_number, img_rows, img_cols))\n",
    "X2_train = np.zeros((sample_number, img_rows, img_cols))\n",
    "y_train = np.zeros((sample_number,))\n",
    "\n",
    "tic = time.time()\n",
    "# Load the training set.\n",
    "hdf5TrainPatchesPath = \"/home/qw2208/research/trainPatches.hdf5\"\n",
    "with h5py.File(hdf5TrainPatchesPath, \"r\") as f1:\n",
    "    for i in xrange(sample_number/2):\n",
    "        X1_train[2*i,:,:] = f1['left/'+str(i)][()]\n",
    "        X1_train[(2*i+1),:,:] = f1['left/'+str(i)][()]\n",
    "        X2_train[2*i,:,:] = f1['rightNeg/'+str(i)][()]\n",
    "        X2_train[(2*i+1),:,:] = f1['rightPos/'+str(i)][()]\n",
    "        y_train[2*i] = 0\n",
    "        y_train[2*i+1] = 1\n",
    "    \n",
    "toc = time.time()\n",
    "print \"Time for loading the training set: \", toc-tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here some additional preprocess methods like rotation etc. could be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Resize the dataset (Trivial)\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    X1_train = X1_train.reshape(X1_train.shape[0], 1, img_rows, img_cols)\n",
    "    X2_train = X2_train.reshape(X2_train.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1,img_rows, img_cols)\n",
    "else:\n",
    "    X1_train = X1_train.reshape(X1_train.shape[0], img_rows, img_cols, 1)\n",
    "    X2_train = X2_train.reshape(X2_train.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly check some patches.\n",
    "Positive-matching patches are expected to be of similar features.\n",
    "We store two left patches in X1_train.\n",
    "One for matching the positve right patch in X2_train. \n",
    "The other for matching negative right patch in X2_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for i in xrange(20,30):\n",
    "#     print 'Check {}'.format(i-19)\n",
    "#     print X1_train[2*i][0]\n",
    "#     # print (X1_train[2*i+1][0]-X2_train[2*i+1][0])\n",
    "\n",
    "X1_train = X1_train.astype('float32')\n",
    "X2_train = X2_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# https://keras-cn.readthedocs.io/en/latest/getting_started/sequential_model/#merge\n",
    "left_branch = Sequential()\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same', input_shape=input_shape))\n",
    "left_branch.add(Activation('relu'))\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "left_branch.add(Activation('relu'))\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "left_branch.add(Activation('relu'))\n",
    "left_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "left_branch.add(Activation('relu'))\n",
    "\n",
    "right_branch = Sequential()\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same', input_shape=input_shape))\n",
    "right_branch.add(Activation('relu'))\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "right_branch.add(Activation('relu'))\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "right_branch.add(Activation('relu'))\n",
    "right_branch.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='same'))\n",
    "right_branch.add(Activation('relu')) \n",
    "\n",
    "merged = Merge([left_branch, right_branch], mode='concat', concat_axis=1)\n",
    "fc = Sequential()\n",
    "fc.add(merged)\n",
    "fc.add(Flatten())\n",
    "fc.add(Dense(384, activation='relu'))\n",
    "fc.add(Dense(384, activation='relu'))\n",
    "fc.add(Dense(384, activation='relu'))\n",
    "\n",
    "fc.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "fc.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "fc.fit([X1_train,X2_train], y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0, shuffle=True, callbacks=[TQDMNotebookCallback()])\n",
    "\n",
    "# Evaluate the result based on the training set\n",
    "score = fc.evaluate([X1_train,X2_train], y_train, verbose=0)\n",
    "print('Test score: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We need to store the trained network. This is not finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fc.save('/home/qw2208/research/weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
